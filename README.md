## Team members
- Jayeon Koo (jk7134)
- Wenkai Cao (wc2440)
- Meng-Tse Wu (mw4828)

## Contents
1. Data Augmentation: We tested different data augmentation settings in the notebooks under the folder "DataAugment"
2. Baseline model (model #1): We created the first baseline model in "baseline_noFreeze_v2.ipynb"
3. we tried to test the maximum length of a feature settings in "freezeBert max =512.ipynb", "freezeEmbDistillBert_max_=512.ipynb"
4. we tried to test the transformer types in "freezeEmbDistillBert.ipynb", "freezeBert max =512.ipynb"
5. Final model: We trained our final model over 3 epochs in "freezeEmbOurModel3epochs.ipynb"

## Reference
most of the code of model architecture and training is revised from https://github.com/huggingface/notebooks/blob/main/examples/
